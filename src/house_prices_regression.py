"""
An√°lisis de Regresi√≥n para Precios de Viviendas
Dataset: House Prices - Advanced Regression Techniques
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

def load_and_prepare_data():
    """Carga y prepara los datos para el an√°lisis"""
    try:
        df = pd.read_csv('train.csv')
        print("‚úÖ Datos cargados exitosamente")
        print(f"üìä Dimensiones del dataset: {df.shape}")
        return df
    except FileNotFoundError:
        print("‚ùå Error: No se encontr√≥ el archivo train.csv")
        print("üì• Por favor desc√°rgalo de: https://www.kaggle.com/c/house-prices-advanced-regression-techniques")
        return None

def preprocess_data(df):
    """Preprocesa los datos seleccionando caracter√≠sticas y limpiando valores nulos"""
    # Seleccionar caracter√≠sticas iniciales
    features = ['GrLivArea', 'YearBuilt']
    target = 'SalePrice'
    
    # Verificar que las columnas existen
    for col in features + [target]:
        if col not in df.columns:
            print(f"‚ùå Error: La columna {col} no existe en el dataset")
            return None, None, None, None, None, None
    
    # Limpiar datos
    df_clean = df[features + [target]].dropna()
    print(f"üßπ Datos despu√©s de la limpieza: {df_clean.shape}")
    
    # Separar caracter√≠sticas y variable objetivo
    X = df_clean[features]
    y = df_clean[target]
    
    # Dividir en conjuntos de entrenamiento y prueba
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"üìö Conjunto de entrenamiento: {X_train.shape}")
    print(f"üß™ Conjunto de prueba: {X_test.shape}")
    
    # Estandarizar las caracter√≠sticas
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test, scaler

def train_and_evaluate_models(X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test):
    """Entrena y eval√∫a m√∫ltiples modelos de regresi√≥n"""
    # Definir los modelos
    models = {
        'Linear Regression': LinearRegression(),
        'SVM': SVR(),
        'Decision Tree': DecisionTreeRegressor(random_state=42),
        'Random Forest': RandomForestRegressor(random_state=42)
    }
    
    results = {}
    
    print("\n" + "="*60)
    print("üöÄ ENTRENAMIENTO DE MODELOS")
    print("="*60)
    
    for name, model in models.items():
        print(f"\nüìä Entrenando {name}...")
        
        # Usar datos escalados para SVM, sin escalar para otros modelos
        if name == 'SVM':
            X_tr = X_train_scaled
            X_te = X_test_scaled
        else:
            X_tr = X_train
            X_te = X_test
        
        # Entrenar el modelo
        model.fit(X_tr, y_train)
        
        # Predecir
        y_pred = model.predict(X_te)
        
        # Calcular m√©tricas
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # Almacenar resultados
        results[name] = {
            'model': model,
            'predictions': y_pred,
            'mse': mse,
            'r2': r2,
            'rmse': np.sqrt(mse)
        }
        
        print(f"   ‚úÖ {name} - MSE: {mse:,.2f}, RMSE: {np.sqrt(mse):,.2f}, R¬≤: {r2:.4f}")
    
    return results

def compare_models(results):
    """Compara los resultados de todos los modelos"""
    # Crear tabla de comparaci√≥n
    comparison_df = pd.DataFrame({
        'Model': list(results.keys()),
        'MSE': [results[name]['mse'] for name in results.keys()],
        'RMSE': [results[name]['rmse'] for name in results.keys()],
        'R¬≤': [results[name]['r2'] for name in results.keys()]
    }).sort_values('MSE')
    
    print("\n" + "="*60)
    print("üìà COMPARACI√ìN DE MODELOS")
    print("="*60)
    print(comparison_df.round(4))
    
    # Encontrar el mejor modelo
    best_model_name = comparison_df.iloc[0]['Model']
    best_model_mse = comparison_df.iloc[0]['MSE']
    best_model_rmse = comparison_df.iloc[0]['RMSE']
    best_model_r2 = comparison_df.iloc[0]['R¬≤']
    
    print(f"\nüèÜ MEJOR MODELO: {best_model_name}")
    print(f"   üìâ MSE: {best_model_mse:,.2f}")
    print(f"   üìè RMSE: {best_model_rmse:,.2f}")
    print(f"   üìä R¬≤: {best_model_r2:.4f}")
    
    return comparison_df

def visualize_results(results, X_test, y_test):
    """Crea visualizaciones de los resultados"""
    # Configurar el estilo de las gr√°ficas
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")
    
    # Crear figura con subplots
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.ravel()
    
    # Colores para diferentes modelos
    colors = ['blue', 'red', 'green', 'orange']
    
    # Gr√°fico para cada modelo
    for idx, (name, color) in enumerate(zip(results.keys(), colors)):
        y_pred = results[name]['predictions']
        
        # Gr√°fico de dispersi√≥n: Valores reales vs predichos
        axes[idx].scatter(y_test, y_pred, alpha=0.6, color=color, s=50)
        
        # L√≠nea de perfecta predicci√≥n
        max_val = max(y_test.max(), y_pred.max())
        min_val = min(y_test.min(), y_pred.min())
        axes[idx].plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.7, linewidth=2)
        
        axes[idx].set_xlabel('Valores Reales (SalePrice)')
        axes[idx].set_ylabel('Valores Predichos')
        axes[idx].set_title(f'{name}\nMSE: {results[name]["mse"]:,.2f}, R¬≤: {results[name]["r2"]:.4f}')
        axes[idx].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Gr√°fica de comparaci√≥n de errores
    plt.figure(figsize=(10, 6))
    models_names = list(results.keys())
    mse_values = [results[name]['mse'] for name in models_names]
    
    bars = plt.bar(models_names, mse_values, color=['blue', 'red', 'green', 'orange'], alpha=0.7)
    plt.ylabel('Mean Squared Error (MSE)')
    plt.title('Comparaci√≥n de MSE entre Modelos')
    plt.xticks(rotation=45)
    
    # A√±adir valores en las barras
    for bar, value in zip(bars, mse_values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mse_values)*0.01, 
                f'{value:,.0f}', ha='center', va='bottom')
    
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('mse_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

def advanced_analysis(df):
    """An√°lisis avanzado con m√°s caracter√≠sticas"""
    print("\n" + "="*60)
    print("üîç AN√ÅLISIS AVANZADO CON M√ÅS CARACTER√çSTICAS")
    print("="*60)
    
    # Seleccionar m√°s caracter√≠sticas relevantes
    advanced_features = [
        'GrLivArea', 'YearBuilt', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',
        'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea'
    ]
    target = 'SalePrice'
    
    # Filtrar caracter√≠sticas que existen en el dataset
    available_features = [f for f in advanced_features if f in df.columns]
    print(f"Caracter√≠sticas seleccionadas: {available_features}")
    
    # Limpiar datos
    df_advanced = df[available_features + [target]].dropna()
    print(f"Dataset para an√°lisis avanzado: {df_advanced.shape}")
    
    X_adv = df_advanced[available_features]
    y_adv = df_advanced[target]
    
    # Dividir datos
    X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split(
        X_adv, y_adv, test_size=0.2, random_state=42
    )
    
    # Entrenar Random Forest (mejor modelo del an√°lisis simple)
    rf_advanced = RandomForestRegressor(random_state=42)
    rf_advanced.fit(X_train_adv, y_train_adv)
    
    # Predecir y evaluar
    y_pred_adv = rf_advanced.predict(X_test_adv)
    mse_adv = mean_squared_error(y_test_adv, y_pred_adv)
    r2_adv = r2_score(y_test_adv, y_pred_adv)
    
    print(f"\nüìä Random Forest con {len(available_features)} caracter√≠sticas:")
    print(f"   ‚úÖ MSE: {mse_adv:,.2f}, RMSE: {np.sqrt(mse_adv):,.2f}, R¬≤: {r2_adv:.4f}")
    
    # Importancia de caracter√≠sticas
    feature_importance = pd.DataFrame({
        'feature': available_features,
        'importance': rf_advanced.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüéØ Importancia de caracter√≠sticas:")
    print(feature_importance.round(4))
    
    return feature_importance

def main():
    """Funci√≥n principal"""
    print("üè† AN√ÅLISIS DE REGRESI√ìN PARA PRECIOS DE VIVIENDAS")
    print("="*60)
    
    # 1. Cargar datos
    df = load_and_prepare_data()
    if df is None:
        return
    
    # 2. Preprocesamiento b√°sico
    X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test, scaler = preprocess_data(df)
    if X_train is None:
        return
    
    # 3. Entrenar y evaluar modelos
    results = train_and_evaluate_models(X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test)
    
    # 4. Comparar modelos
    comparison_df = compare_models(results)
    
    # 5. Visualizar resultados
    visualize_results(results, X_test, y_test)
    
    # 6. An√°lisis avanzado
    feature_importance = advanced_analysis(df)
    
    print("\n" + "="*60)
    print("‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE")
    print("="*60)
    print("üìÅ Archivos generados:")
    print("   - model_comparison.png (Comparaci√≥n de predicciones)")
    print("   - mse_comparison.png (Comparaci√≥n de errores)")
    print("\nüí° Conclusiones:")
    print("   - El modelo con menor MSE es el m√°s preciso")
    print("   - R¬≤ cercano a 1 indica mejor ajuste")
    print("   - Random Forest suele funcionar bien con datos estructurados")

if __name__ == "__main__":
    main()
